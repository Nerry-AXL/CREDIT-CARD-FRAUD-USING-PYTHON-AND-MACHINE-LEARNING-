{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8820b441",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection Using Python & Machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a1f6db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, MinMaxScaler, MaxAbsScaler\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmf\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtsa\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression, LinearRegression, ElasticNet, Lasso, Ridge\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing related to general operating system & warnings\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#importing related to data importing, manipulation, exploratory data #analysis, data understanding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from termcolor import colored as cl # text customization\n",
    "#importing related to data visualizaiton\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#Setting the plot sizes and type of plot\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.gray()\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import  PolynomialFeatures, KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa as tsa\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz, export_text\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor \n",
    "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing and reading dataset\n",
    "data=pd.read_csv(\"creditcard.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac942f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_transactions = len(data)\n",
    "normal = len(data[data.Class == 0])\n",
    "fraudulent = len(data[data.Class == 1])\n",
    "fraud_percentage = round(fraudulent/normal*100, 2)\n",
    "print(cl('Total number of Trnsactions are {}'.format(Total_transactions), attrs = ['bold']))\n",
    "print(cl('Number of Normal Transactions are {}'.format(normal), attrs = ['bold']))\n",
    "print(cl('Number of fraudulent Transactions are {}'.format(fraudulent), attrs = ['bold']))\n",
    "print(cl('Percentage of fraud Transactions is {}'.format(fraud_percentage), attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Processing & Understanding \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler() \n",
    "amount = data['Amount'].values \n",
    "data['Amount'] = sc.fit_transform(amount.reshape(-1, 1)) \n",
    "data.drop(['Time'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ad074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any duplicates in the Dataset. \n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47fcd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling the Train & Test after defining the dependent and independent variables. The dependent variable is also known as X and the independent variable is known as y.\n",
    "X = data.drop('Class', axis = 1).values \n",
    "y = data['Class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c5fa4",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95aa6a",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07a40c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy') \n",
    "DT.fit(X_train, y_train)\n",
    "tree_yhat = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the accuracy of our decision tree model. \n",
    "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, tree_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking F1-Score for the decision tree model. \n",
    "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, tree_yhat))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e517df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the confusion matrix: \n",
    "confusion_matrix(y_test, tree_yhat, labels = [0, 1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9988329",
   "metadata": {},
   "source": [
    "Here, the first row represents positive and the second row represents negative. \n",
    "So, we have 68782 as true positive and 18 are false positive. \n",
    "That says, out of 68782+18=68800, we have 68782 that are successfully classified as a normal transaction and 18 were falsely classified as normal — but they were fraudulent. \n",
    "Let’s now try different models and check their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178c40c",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7 \n",
    "KNN = KNeighborsClassifier(n_neighbors = n) \n",
    "KNN.fit(X_train, y_train) \n",
    "knn_yhat = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the accuracy of the K-Nearest Neighbors model.\n",
    "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking F1-Score for the K-Nearest Neighbors model.\n",
    " print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30439d88",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression() \n",
    "lr.fit(X_train, y_train) \n",
    "lr_yhat = lr.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c87c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the accuracy of the Logistic Regression model. \n",
    "print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b7752",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Checking F1-Score for the Logistic Regression model. \n",
    "print('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167069d3",
   "metadata": {},
   "source": [
    "# Support Vector Machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7503c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC() \n",
    "svm.fit(X_train, y_train) \n",
    "svm_yhat = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36edddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the accuracy of the Support Vector Machines (SVM) model.\n",
    "print('Accuracy score of the Support Vector Machines model is {}'.format(accuracy_score(y_test, svm_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1189caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking F1-Score for the Support Vector Machines model. \n",
    "print('F1 score of the Support Vector Machines model is {}'.format(f1_score(y_test, svm_yhat))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd5196",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43912bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 4) \n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the accuracy of our Random Forest model.\n",
    "print('Accuracy score of the Random Forest model is {}'.format(accuracy_score(y_test, rf_yhat))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking F1-Score for the Random Forest model. \n",
    "print('F1 score of the Random Forest model is {}'.format(f1_score(y_test, rf_yhat))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448c21c",
   "metadata": {},
   "source": [
    "# Xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth = 4) \n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304debbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s check the accuracy of our XGBoost model.\n",
    "print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking F1-Score for the XGBoost model.\n",
    "print('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebffa3",
   "metadata": {},
   "source": [
    "# CONCLUSION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0bf61",
   "metadata": {},
   "source": [
    "We achieved 99.95% accuracy in our credit card fraud detection system. \n",
    "This number should not be surprising due to the fact that our data was balanced towards one class. \n",
    "The good thing that we have noticed from the confusion matrix is that — our model is not overfitted. \n",
    "Finally, based on our accuracy score — XGBoost is the best performing model for our case. \n",
    "The only catch here is the data that we have received for model training. \n",
    "The data features are the transformed version of PCA. \n",
    "If the actual features follow a similar pattern then we are on the right track.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
